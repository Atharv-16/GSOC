{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atharv-16/GSOC/blob/main/Current-Progress/dino_with_equiv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and extracting dataset"
      ],
      "metadata": {
        "id": "AkRbLeqKR4Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown --id 1aafE2nDp7S6j59sZcBIzP3FnQxVCmHCx\n",
        "!unzip real_hst.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyvWhfQ1Cvhs",
        "outputId": "6a20817f-9535-4ac4-f23a-16bb75217f5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.7.3\n",
            "    Uninstalling gdown-4.7.3:\n",
            "      Successfully uninstalled gdown-4.7.3\n",
            "Successfully installed gdown-5.1.0\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1aafE2nDp7S6j59sZcBIzP3FnQxVCmHCx\n",
            "From (redirected): https://drive.google.com/uc?id=1aafE2nDp7S6j59sZcBIzP3FnQxVCmHCx&confirm=t&uuid=30ba8252-ac2c-41a9-b2af-fe17fa1f95b9\n",
            "To: /content/real_hst.zip\n",
            "100% 80.5M/80.5M [00:00<00:00, 167MB/s]\n",
            "Archive:  real_hst.zip\n",
            "   creating: real_hst/\n",
            "  inflating: real_hst/nl_269_hst.npy  \n",
            "  inflating: real_hst/75_hst.npy     \n",
            "  inflating: real_hst/65_hst.npy     \n",
            "  inflating: real_hst/nl_301_hst.npy  \n",
            "  inflating: real_hst/9372_hst.npy   \n",
            "  inflating: real_hst/17_hst.npy     \n",
            "  inflating: real_hst/nl_189_hst.npy  \n",
            "  inflating: real_hst/9059_hst.npy   \n",
            "  inflating: real_hst/111_hst.npy    \n",
            "  inflating: real_hst/28_hst.npy     \n",
            "  inflating: real_hst/38_hst.npy     \n",
            "  inflating: real_hst/7156_hst.npy   \n",
            "  inflating: real_hst/7866_hst.npy   \n",
            "  inflating: real_hst/9225_hst.npy   \n",
            "  inflating: real_hst/91_hst.npy     \n",
            "  inflating: real_hst/81_hst.npy     \n",
            "  inflating: real_hst/nl_15_hst.npy  \n",
            "  inflating: real_hst/nl_174_hst.npy  \n",
            "  inflating: real_hst/nl_202_hst.npy  \n",
            "  inflating: real_hst/nl_260_hst.npy  \n",
            "  inflating: real_hst/6963_hst.npy   \n",
            "  inflating: real_hst/31_hst.npy     \n",
            "  inflating: real_hst/21_hst.npy     \n",
            "  inflating: real_hst/88_hst.npy     \n",
            "  inflating: real_hst/nl_48_hst.npy  \n",
            "  inflating: real_hst/118_hst.npy    \n",
            "  inflating: real_hst/6751_hst.npy   \n",
            "  inflating: real_hst/53_hst.npy     \n",
            "  inflating: real_hst/43_hst.npy     \n",
            "  inflating: real_hst/nl_165_hst.npy  \n",
            "  inflating: real_hst/nl_4_hst.npy   \n",
            "  inflating: real_hst/7171_hst.npy   \n",
            "  inflating: real_hst/126_hst.npy    \n",
            "  inflating: real_hst/136_hst.npy    \n",
            "  inflating: real_hst/nl_319_hst.npy  \n",
            "  inflating: real_hst/nl_261_hst.npy  \n",
            "  inflating: real_hst/89_hst.npy     \n",
            "  inflating: real_hst/20_hst.npy     \n",
            "  inflating: real_hst/30_hst.npy     \n",
            "  inflating: real_hst/nl_128_hst.npy  \n",
            "  inflating: real_hst/nl_326_hst.npy  \n",
            "  inflating: real_hst/42_hst.npy     \n",
            "  inflating: real_hst/52_hst.npy     \n",
            "  inflating: real_hst/119_hst.npy    \n",
            "  inflating: real_hst/nl_181_hst.npy  \n",
            "  inflating: real_hst/64_hst.npy     \n",
            "  inflating: real_hst/74_hst.npy     \n",
            "  inflating: real_hst/7168_hst.npy   \n",
            "  inflating: real_hst/21100_hst.npy  \n",
            "  inflating: real_hst/7125_hst.npy   \n",
            "  inflating: real_hst/100_hst.npy    \n",
            "  inflating: real_hst/7096_hst.npy   \n",
            "  inflating: real_hst/80_hst.npy     \n",
            "  inflating: real_hst/90_hst.npy     \n",
            "  inflating: real_hst/39_hst.npy     \n",
            "  inflating: real_hst/nl_225_hst.npy  \n",
            "  inflating: real_hst/29_hst.npy     \n",
            "  inflating: real_hst/7147_hst.npy   \n",
            "  inflating: real_hst/134_hst.npy    \n",
            "  inflating: real_hst/7111_hst.npy   \n",
            "  inflating: real_hst/nl_211_hst.npy  \n",
            "  inflating: real_hst/nl_6_hst.npy   \n",
            "  inflating: real_hst/2745_hst.npy   \n",
            "  inflating: real_hst/9368_hst.npy   \n",
            "  inflating: real_hst/nl_334_hst.npy  \n",
            "  inflating: real_hst/50_hst.npy     \n",
            "  inflating: real_hst/40_hst.npy     \n",
            "  inflating: real_hst/32_hst.npy     \n",
            "  inflating: real_hst/22_hst.npy     \n",
            "  inflating: real_hst/nl_208_hst.npy  \n",
            "  inflating: real_hst/7_hst.npy      \n",
            "  inflating: real_hst/76_hst.npy     \n",
            "  inflating: real_hst/66_hst.npy     \n",
            "  inflating: real_hst/12334_hst.npy  \n",
            "  inflating: real_hst/92_hst.npy     \n",
            "  inflating: real_hst/82_hst.npy     \n",
            "  inflating: real_hst/49_hst.npy     \n",
            "  inflating: real_hst/59_hst.npy     \n",
            "  inflating: real_hst/11839_hst.npy  \n",
            "  inflating: real_hst/nl_219_hst.npy  \n",
            "  inflating: real_hst/15_hst.npy     \n",
            "  inflating: real_hst/67_hst.npy     \n",
            "  inflating: real_hst/77_hst.npy     \n",
            "  inflating: real_hst/6_hst.npy      \n",
            "  inflating: real_hst/20900_hst.npy  \n",
            "  inflating: real_hst/nl_150_hst.npy  \n",
            "  inflating: real_hst/83_hst.npy     \n",
            "  inflating: real_hst/93_hst.npy     \n",
            "  inflating: real_hst/nl_31_hst.npy  \n",
            "  inflating: real_hst/15800_hst.npy  \n",
            "  inflating: real_hst/103_hst.npy    \n",
            "  inflating: real_hst/58_hst.npy     \n",
            "  inflating: real_hst/48_hst.npy     \n",
            "  inflating: real_hst/7240_hst.npy   \n",
            "  inflating: real_hst/2726_hst.npy   \n",
            "  inflating: real_hst/135_hst.npy    \n",
            "  inflating: real_hst/8036_hst.npy   \n",
            "  inflating: real_hst/9369_hst.npy   \n",
            "  inflating: real_hst/nl_210_hst.npy  \n",
            "  inflating: real_hst/nl_176_hst.npy  \n",
            "  inflating: real_hst/41_hst.npy     \n",
            "  inflating: real_hst/51_hst.npy     \n",
            "  inflating: real_hst/33_hst.npy     \n",
            "  inflating: real_hst/6798_hst.npy   \n",
            "  inflating: real_hst/nl_286_hst.npy  \n",
            "  inflating: real_hst/nl_296_hst.npy  \n",
            "  inflating: real_hst/nl_187_hst.npy  \n",
            "  inflating: real_hst/54_hst.npy     \n",
            "  inflating: real_hst/nl_330_hst.npy  \n",
            "  inflating: real_hst/44_hst.npy     \n",
            "  inflating: real_hst/36_hst.npy     \n",
            "  inflating: real_hst/26_hst.npy     \n",
            "  inflating: real_hst/nl_293_hst.npy  \n",
            "  inflating: real_hst/130_hst.npy    \n",
            "  inflating: real_hst/120_hst.npy    \n",
            "  inflating: real_hst/9441_hst.npy   \n",
            "  inflating: real_hst/nl_205_hst.npy  \n",
            "  inflating: real_hst/nl_155_hst.npy  \n",
            "  inflating: real_hst/nl_34_hst.npy  \n",
            "  inflating: real_hst/86_hst.npy     \n",
            "  inflating: real_hst/10_hst.npy     \n",
            "  inflating: real_hst/72_hst.npy     \n",
            "  inflating: real_hst/3_hst.npy      \n",
            "  inflating: real_hst/62_hst.npy     \n",
            "  inflating: real_hst/nl_306_hst.npy  \n",
            "  inflating: real_hst/129_hst.npy    \n",
            "  inflating: real_hst/7091_hst.npy   \n",
            "  inflating: real_hst/87_hst.npy     \n",
            "  inflating: real_hst/97_hst.npy     \n",
            "  inflating: real_hst/7150_hst.npy   \n",
            "  inflating: real_hst/nl_144_hst.npy  \n",
            "  inflating: real_hst/nl_154_hst.npy  \n",
            "  inflating: real_hst/nl_136_hst.npy  \n",
            "  inflating: real_hst/9380_hst.npy   \n",
            "  inflating: real_hst/nl_57_hst.npy  \n",
            "  inflating: real_hst/11_hst.npy     \n",
            "  inflating: real_hst/9364_hst.npy   \n",
            "  inflating: real_hst/63_hst.npy     \n",
            "  inflating: real_hst/2208_hst.npy   \n",
            "  inflating: real_hst/2_hst.npy      \n",
            "  inflating: real_hst/73_hst.npy     \n",
            "  inflating: real_hst/nl_109_hst.npy  \n",
            "  inflating: real_hst/2643_hst.npy   \n",
            "  inflating: real_hst/nl_321_hst.npy  \n",
            "  inflating: real_hst/45_hst.npy     \n",
            "  inflating: real_hst/55_hst.npy     \n",
            "  inflating: real_hst/nl_331_hst.npy  \n",
            "  inflating: real_hst/nl_292_hst.npy  \n",
            "  inflating: real_hst/27_hst.npy     \n",
            "  inflating: real_hst/37_hst.npy     \n",
            "  inflating: real_hst/7149_hst.npy   \n",
            "  inflating: real_hst/121_hst.npy    \n",
            "  inflating: real_hst/131_hst.npy    \n",
            "  inflating: real_hst/nl_162_hst.npy  \n",
            "  inflating: real_hst/nl_172_hst.npy  \n",
            "  inflating: real_hst/18_hst.npy     \n",
            "  inflating: real_hst/8667_hst.npy   \n",
            "  inflating: real_hst/nl_252_hst.npy  \n",
            "  inflating: real_hst/nl_124_hst.npy  \n",
            "  inflating: real_hst/105_hst.npy    \n",
            "  inflating: real_hst/85_hst.npy     \n",
            "  inflating: real_hst/38200_hst.npy  \n",
            "  inflating: real_hst/nl_299_hst.npy  \n",
            "  inflating: real_hst/nl_230_hst.npy  \n",
            "  inflating: real_hst/nl_220_hst.npy  \n",
            "  inflating: real_hst/71_hst.npy     \n",
            "  inflating: real_hst/nl_305_hst.npy  \n",
            "  inflating: real_hst/61_hst.npy     \n",
            "  inflating: real_hst/13_hst.npy     \n",
            "  inflating: real_hst/7935_hst.npy   \n",
            "  inflating: real_hst/8141_hst.npy   \n",
            "  inflating: real_hst/nl_280_hst.npy  \n",
            "  inflating: real_hst/35_hst.npy     \n",
            "  inflating: real_hst/nl_97_hst.npy  \n",
            "  inflating: real_hst/25_hst.npy     \n",
            "  inflating: real_hst/nl_333_hst.npy  \n",
            "  inflating: real_hst/57_hst.npy     \n",
            "  inflating: real_hst/47_hst.npy     \n",
            "  inflating: real_hst/7164_hst.npy   \n",
            "  inflating: real_hst/255_hst.npy    \n",
            "  inflating: real_hst/133_hst.npy    \n",
            "  inflating: real_hst/68_hst.npy     \n",
            "  inflating: real_hst/78_hst.npy     \n",
            "  inflating: real_hst/9_hst.npy      \n",
            "  inflating: real_hst/nl_264_hst.npy  \n",
            "  inflating: real_hst/nl_96_hst.npy  \n",
            "  inflating: real_hst/34_hst.npy     \n",
            "  inflating: real_hst/nl_281_hst.npy  \n",
            "  inflating: real_hst/nl_291_hst.npy  \n",
            "  inflating: real_hst/46_hst.npy     \n",
            "  inflating: real_hst/nl_322_hst.npy  \n",
            "  inflating: real_hst/56_hst.npy     \n",
            "  inflating: real_hst/24400_hst.npy  \n",
            "  inflating: real_hst/9443_hst.npy   \n",
            "  inflating: real_hst/8_hst.npy      \n",
            "  inflating: real_hst/79_hst.npy     \n",
            "  inflating: real_hst/nl_275_hst.npy  \n",
            "  inflating: real_hst/69_hst.npy     \n",
            "  inflating: real_hst/nl_72_hst.npy  \n",
            "  inflating: real_hst/122_hst.npy    \n",
            "  inflating: real_hst/132_hst.npy    \n",
            "  inflating: real_hst/6940_hst.npy   \n",
            "  inflating: real_hst/2707_hst.npy   \n",
            "  inflating: real_hst/nl_298_hst.npy  \n",
            "  inflating: real_hst/84_hst.npy     \n",
            "  inflating: real_hst/94_hst.npy     \n",
            "  inflating: real_hst/nl_36_hst.npy  \n",
            "  inflating: real_hst/7092_hst.npy   \n",
            "  inflating: real_hst/7268_hst.npy   \n",
            "  inflating: real_hst/60_hst.npy     \n",
            "  inflating: real_hst/1_hst.npy      \n",
            "  inflating: real_hst/70_hst.npy     \n",
            "  inflating: real_hst/7934_hst.npy   \n",
            "  inflating: real_hst/6710_hst.npy   \n",
            "  inflating: real_hst/nl_178_hst.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading Equivariant Network Source Codes"
      ],
      "metadata": {
        "id": "DcBN8d5iR8Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ML4SCI/DeepLense.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB3PHYi-xbMX",
        "outputId": "0e6f8589-a653-41ab-db6e-5eef2b59aabd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepLense'...\n",
            "remote: Enumerating objects: 2217, done.\u001b[K\n",
            "remote: Counting objects: 100% (551/551), done.\u001b[K\n",
            "remote: Compressing objects: 100% (288/288), done.\u001b[K\n",
            "remote: Total 2217 (delta 335), reused 423 (delta 261), pack-reused 1666\u001b[K\n",
            "Receiving objects: 100% (2217/2217), 535.78 MiB | 26.84 MiB/s, done.\n",
            "Resolving deltas: 100% (1040/1040), done.\n",
            "Updating files: 100% (823/823), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important Instruction**: You will have to change line 74 to **return F.grid_sample(x, grid)** and comment from 75 to 82 in DeepLense/Equivariant_Neural_Networks_for_DeepLense_GEO/models/equivariant_transformers/network.py and then restart runtime\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "0UDXIDBHRllb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Input and output directories\n",
        "input_folder = \"./real_hst\"\n",
        "output_folder = \"./output_folder\"\n",
        "\n",
        "# Create output directories for classes\n",
        "nl_folder = os.path.join(output_folder, \"nl\")\n",
        "others_folder = os.path.join(output_folder, \"others\")\n",
        "os.makedirs(nl_folder, exist_ok=True)\n",
        "os.makedirs(others_folder, exist_ok=True)\n",
        "\n",
        "# Iterate through files in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".npy\"):\n",
        "        filepath = os.path.join(input_folder, filename)\n",
        "        # Load the numpy array\n",
        "        data = np.load(filepath)\n",
        "        # Determine class based on filename\n",
        "        if filename.startswith(\"nl\"):\n",
        "            class_folder = nl_folder\n",
        "        else:\n",
        "            class_folder = others_folder\n",
        "        # Convert array to image and save\n",
        "        img_path = os.path.join(class_folder, filename.replace(\".npy\", \".png\"))\n",
        "        plt.imsave(img_path, data, cmap='gray')  # Adjust colormap as needed\n"
      ],
      "metadata": {
        "id": "9XieY6kDDDB-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "8crkb1F2SCrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random"
      ],
      "metadata": {
        "id": "1yzEWqhIFfbV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seed"
      ],
      "metadata": {
        "id": "5TRTSErQSFjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(no):\n",
        "    torch.manual_seed(no)\n",
        "    random.seed(no)\n",
        "    np.random.seed(no)\n",
        "    os.environ['PYTHONHASHSEED'] = str()\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(100)"
      ],
      "metadata": {
        "id": "625q1cUXLdCE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1faPJhAID3x",
        "outputId": "2635773d-1177-48ae-eb60-36850d257ed9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing and data loaders"
      ],
      "metadata": {
        "id": "-chw-097SIuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "# Define data transformations\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Set the directory containing your data\n",
        "data_dir = '/content/output_folder'\n",
        "\n",
        "# Use ImageFolder to load data\n",
        "image_dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
        "\n",
        "# Split the dataset into train and test sets (80% train, 20% test)\n",
        "train_size = int(0.8 * len(image_dataset))\n",
        "test_size = len(image_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(image_dataset, [train_size, test_size])\n",
        "\n",
        "# Create data loaders\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_dataset, batch_size=6, shuffle=True, num_workers=4),\n",
        "    'test': DataLoader(test_dataset, batch_size=6, shuffle=False, num_workers=4)\n",
        "}\n",
        "\n",
        "# Get class names\n",
        "class_names = image_dataset.classes\n",
        "\n",
        "# Get dataset sizes\n",
        "dataset_sizes = {'train': len(train_dataset), 'test': len(test_dataset)}\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX-5d8aBFMFs",
        "outputId": "61eaf164-e8a5-444c-ec92-4d9de204a007"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETyB-ag-GcWN",
        "outputId": "539bc838-6134-4540-b73f-de51394c32b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7e1cd66476a0>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7e1cd66470a0>}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd /content/DeepLense/Equivariant_Neural_Networks_for_DeepLense_GEO\n",
        "!pip install e2cnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVJYw-z_lko-",
        "outputId": "63ead39f-530b-47e7-bd3d-db2589945c0b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting e2cnn\n",
            "  Downloading e2cnn-0.2.3-py3-none-any.whl (225 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/225.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/225.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from e2cnn) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from e2cnn) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from e2cnn) (1.11.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from e2cnn) (1.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->e2cnn) (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (4.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->e2cnn)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->e2cnn)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->e2cnn)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->e2cnn)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->e2cnn)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->e2cnn)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->e2cnn)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->e2cnn)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->e2cnn)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->e2cnn)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->e2cnn)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->e2cnn)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->e2cnn) (2.1.5)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, e2cnn\n",
            "Successfully installed e2cnn-0.2.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DINO Model\n"
      ],
      "metadata": {
        "id": "NyaNnftEH278"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dino model\n",
        "dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz4BJWf2H7I2",
        "outputId": "392a8ec1-32dd-4e16-e9c8-919988cc3676"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
            "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
            "  warnings.warn(\"xFormers is not available (Attention)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
            "  warnings.warn(\"xFormers is not available (Block)\")\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vits14/dinov2_vits14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vits14_pretrain.pth\n",
            "100%|██████████| 84.2M/84.2M [00:00<00:00, 119MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DeepLense/Equivariant_Neural_Networks_for_DeepLense_GEO/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZof0A1nrCqG",
        "outputId": "1be92b67-a63e-458b-d3d7-81a8fa604f24"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepLense/Equivariant_Neural_Networks_for_DeepLense_GEO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing Equivariant Transformer"
      ],
      "metadata": {
        "id": "NXb7kk_7STTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models import coordinates, networks, transformers, ET\n",
        "\n",
        "tf_default_opts = {\n",
        "    \"in_channels\": 3,  # Output channels of DINO model\n",
        "    \"kernel_size\": 3,\n",
        "    \"nf\": 32,\n",
        "    \"strides\": (2, 1),\n",
        "}\n",
        "\n",
        "et_default_opts = {\n",
        "    \"input_channels\": 3,  # Output channels of DINO model\n",
        "    \"output_size\": 3,  # Number of classes\n",
        "    \"nf\": 32,\n",
        "    \"p_dropout\": 0.3,\n",
        "    \"pad_mode\": (None, \"cyclic\"),\n",
        "    \"pool\": (True, True, False),\n",
        "}\n",
        "\n",
        "ET_ = ET(\n",
        "    tfs=[\n",
        "        transformers.ShearX,\n",
        "        transformers.HyperbolicRotation,\n",
        "        transformers.PerspectiveX,\n",
        "        transformers.PerspectiveY,\n",
        "    ],\n",
        "    coords=coordinates.logpolar_grid,\n",
        "    net=networks.BasicCNN,\n",
        "    equivariant=True,\n",
        "    tf_opts=tf_default_opts,\n",
        "    net_opts=et_default_opts,\n",
        ")"
      ],
      "metadata": {
        "id": "_IVCGMEYvU_g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Parameters"
      ],
      "metadata": {
        "id": "Gkv32zSXSZNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import gc\n",
        "lr = 0.0001\n",
        "epochs = 30\n",
        "gamma = 0.5\n",
        "batch_size = 64\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "ET_.model = ET_.model.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(ET_.model.parameters(), lr=0.00001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=gamma)"
      ],
      "metadata": {
        "id": "C0cvs-smu8Su"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ncalK0W2Sdby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_loss = []\n",
        "all_test_loss = []\n",
        "all_train_accuracy = []\n",
        "all_test_accuracy = []\n",
        "\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(3):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    correct, total = 0, 0\n",
        "    ET_.model.train()\n",
        "    tr_loss_epoch = []\n",
        "    test_loss_epoch = []\n",
        "    _ep = 0\n",
        "    for data, label in tqdm(dataloaders['train']):\n",
        "        # print(data.shape)\n",
        "        if _ep%100 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "        output = ET_.model(data)\n",
        "        output=dinov2_vits14(output)\n",
        "        output=nn.Sequential(\n",
        "            nn.Linear(384, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2))(output)\n",
        "\n",
        "        loss = criterion(output, label)\n",
        "        tr_loss_epoch.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        acc = (output.argmax(dim=1) == label).sum()\n",
        "        correct += acc.item()\n",
        "        total += len(label)\n",
        "\n",
        "        epoch_loss += loss.item() / len(dataloaders['train'])\n",
        "        _ep += 1\n",
        "    scheduler.step()\n",
        "    all_train_loss.append(np.asarray(tr_loss_epoch))\n",
        "    all_train_accuracy.append(correct / total * 100)\n",
        "    epoch_accuracy = (correct / total) * 100\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    with torch.no_grad():\n",
        "        epoch_val_accuracy = 0\n",
        "        epoch_val_loss = 0\n",
        "        for data, label in tqdm(dataloaders['test']):\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            output = ET_.model(data)\n",
        "            output=dinov2_vits14(output)\n",
        "            val_output=nn.Sequential(\n",
        "            nn.Linear(384, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2))(output)\n",
        "            # print(\"val\",val_output.shape)\n",
        "            # print(val_output)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f}% - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}%\"\n",
        "    )\n",
        "ET_._save(\"equi_nn.pth\")\n",
        "all_train_loss_mean = [j.mean() for j in all_train_loss]\n",
        "all_test_loss_mean = [j.mean() for j in all_test_loss]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTXeMq96ut2Z",
        "outputId": "7f816c4e-b065-461d-f8e0-2ef2640e6a1f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [02:45<00:00,  5.69s/it]\n",
            "100%|██████████| 8/8 [00:14<00:00,  1.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 - loss : 0.7060 - acc: 55.2326% - val_loss : 0.0000 - val_acc: 0.0000%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [02:42<00:00,  5.61s/it]\n",
            "100%|██████████| 8/8 [00:14<00:00,  1.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 2 - loss : 0.7147 - acc: 56.3953% - val_loss : 0.0000 - val_acc: 0.0000%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [02:45<00:00,  5.71s/it]\n",
            "100%|██████████| 8/8 [00:14<00:00,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 3 - loss : 0.7806 - acc: 50.5814% - val_loss : 0.0000 - val_acc: 0.0000%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "e7GHOqmINdv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correct = 0\n",
        "# total = 0\n",
        "# # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "# with torch.no_grad():\n",
        "#     for data in dataloaders[\"test\"]:\n",
        "#         images, labels = data\n",
        "#         # calculate outputs by running images through the network\n",
        "#         outputs = model(images.to(device))\n",
        "#         # the class with the highest energy is what we choose as prediction\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted.to(\"cpu\") == labels).sum().item()\n",
        "\n",
        "# print(f'Accuracy of the network on the {len(dataloaders[\"test\"])*6} test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "-N9x3KW6I8JF"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}